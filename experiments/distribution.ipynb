{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "if 'experiments' in current_directory:\n",
    "    parent_directory = os.path.dirname(current_directory)\n",
    "    os.chdir(parent_directory)\n",
    "num_classes = 19\n",
    "exp = 'distribution'\n",
    "\n",
    "def read_exp_dir(ds, exp='table'):\n",
    "    exp_dir = f'log/{ds}/{exp}'\n",
    "    overall_dict = {}\n",
    "    for file in tqdm(glob.glob(os.path.join(exp_dir, '*.pkl'))[:100], desc=f'reading from {exp_dir}'):\n",
    "        d = pickle.load(open(file, 'rb'))\n",
    "        filename = os.path.basename(file).replace('.pkl', '')\n",
    "        new_d = {}\n",
    "        new_d[filename] = d[filename]\n",
    "        d = new_d\n",
    "        for image_name, image_d in d.items():\n",
    "            for model_type, model_d in image_d.items():\n",
    "                if model_type not in overall_dict:\n",
    "                    overall_dict[model_type] = {}\n",
    "                for metric, value in model_d.items():\n",
    "                    if isinstance(value, dict):\n",
    "                        for k, v in value.items():\n",
    "                            if isinstance(v, dict):\n",
    "                                if metric not in overall_dict[model_type]:\n",
    "                                    overall_dict[model_type][metric] = {}\n",
    "                                if k not in overall_dict[model_type][metric]:\n",
    "                                    overall_dict[model_type][metric][k] = {}\n",
    "                                for k_, v_ in v.items():\n",
    "                                    if k_ not in overall_dict[model_type][metric][k]:\n",
    "                                        overall_dict[model_type][metric][k][k_] = v_\n",
    "                                    else:\n",
    "                                        overall_dict[model_type][metric][k][k_] += v_\n",
    "                            else:\n",
    "                                if k not in overall_dict[model_type]:\n",
    "                                    overall_dict[model_type][k] = v\n",
    "                                else:\n",
    "                                    overall_dict[model_type][k] += v\n",
    "                                \n",
    "                        continue\n",
    "                    if metric not in overall_dict[model_type]:\n",
    "                        overall_dict[model_type][metric] = value\n",
    "                    else:\n",
    "                        overall_dict[model_type][metric] += value\n",
    "    return overall_dict\n",
    "\n",
    "dir_dict = {}\n",
    "for ds in ['cityscapes', 'acdc', 'cocostuff', 'pascal_ctx']:\n",
    "    dir_dict[ds] = read_exp_dir(ds, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_numbers(numbers, target_sum=100.0):\n",
    "    # Step 1: Scale the numbers and the target sum by 10\n",
    "    scaled_numbers = [num * 10 for num in numbers]\n",
    "    scaled_target_sum = int(target_sum * 10)\n",
    "\n",
    "    # Step 2: Basic rounding and calculate the preliminary sum\n",
    "    rounded = [round(num) for num in scaled_numbers]\n",
    "    rounded_sum = __builtins__.sum(rounded)\n",
    "    \n",
    "    # Step 3: Calculate the difference needed to reach the scaled target sum\n",
    "    diff = scaled_target_sum - rounded_sum\n",
    "\n",
    "    # Step 4: Calculate fractional parts and adjust if needed\n",
    "    if diff != 0:\n",
    "        remainders = [(num - int(num), index) for index, num in enumerate(scaled_numbers)]\n",
    "        remainders.sort(reverse=True, key=lambda x: x[0])  # Sort by fractional remainder, largest first\n",
    "        adjustment_indices = [index for _, index in remainders[:abs(diff)]]  # Adjust based on the largest remainders\n",
    "        \n",
    "        for i in adjustment_indices:\n",
    "            if diff > 0:\n",
    "                rounded[i] += 1\n",
    "            else:\n",
    "                rounded[i] -= 1\n",
    "\n",
    "    # Step 5: Scale back the rounded numbers\n",
    "    final_rounded = [round(num / 10, 1) for num in rounded]\n",
    "\n",
    "    return final_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "font = {'family' : 'serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 12}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "fig, axes = plt.subplots(4, 1, figsize=(7,8), sharex=True)\n",
    "fig.subplots_adjust(hspace=0.2)  # Adjust the value (0.5 in this case) based on your preference\n",
    "gdata = {}\n",
    "for ds, ds_dict in dir_dict.items():\n",
    "    gdata[ds] = {'Ours': [], 'Baseline': []}\n",
    "    for model_type, model_dict in ds_dict.items():\n",
    "        if isinstance(model_type, tuple):\n",
    "            n, n0, f, hi, sigma, tau = model_type\n",
    "            if f != None:\n",
    "                for k, v in model_dict.items():\n",
    "                    if k != 'h_distribution_dict': continue\n",
    "                    abstain = 0\n",
    "                    for level in range(4):\n",
    "                        if level not in v: \n",
    "                            gdata[ds]['Ours'].append(0)\n",
    "                            continue\n",
    "                        level_d = v[level]\n",
    "                        certified_per_level = level_d['certified_per_level']/model_dict['num_pixels']*100\n",
    "                        abstain += level_d['abstain_per_level']/model_dict['num_pixels']*100\n",
    "                        if f != None: # adaptivecertify\n",
    "                            gdata[ds]['Ours'].append(certified_per_level)\n",
    "            else:\n",
    "                gdata[ds]['Baseline'] = [0]*4\n",
    "                gdata[ds]['Baseline'][0] = model_dict['certified_count']/model_dict['num_pixels']*100\n",
    "\n",
    "                        \n",
    "            if f != None: # adaptivecertify\n",
    "                gdata[ds]['Ours'].append(abstain)\n",
    "                gdata[ds]['Ours'] = round_numbers(gdata[ds]['Ours'])\n",
    "            else:\n",
    "                gdata[ds]['Baseline'].append(model_dict['abstain_count']/model_dict['num_pixels']*100)\n",
    "                gdata[ds]['Baseline'] = round_numbers(gdata[ds]['Baseline'])\n",
    "\n",
    "\n",
    "colors = ['green', 'limegreen', 'lime', 'palegreen', 'silver']\n",
    "colx = 0\n",
    "ds_map = {'cityscapes': 'Cityscapes', 'acdc': 'ACDC', 'pascal_ctx': 'PASCAL-Context', 'cocostuff':'COCO-Stuff-10K'}\n",
    "\n",
    "for colx, ds in enumerate(['cityscapes', 'acdc', 'pascal_ctx', 'cocostuff']):\n",
    "    gdata_ds = gdata[ds]\n",
    "    labels = list(gdata_ds.keys()) \n",
    "    data = np.array(list(gdata_ds.values()))\n",
    "    data_cum = data.cumsum(axis=1)\n",
    "    axes[colx].invert_yaxis()\n",
    "    minx = 65\n",
    "    axes[colx].set_xlim(minx, 100)\n",
    "    category_names = [f'Certified $H_{i}$' for i in range(4)] + ['$\\oslash$']\n",
    "\n",
    "    for i, (colname, color) in enumerate(zip(category_names, colors)):\n",
    "        widths = data[:, i]\n",
    "        starts = data_cum[:, i] - widths\n",
    "        axes[colx].barh(labels, widths, left=starts, label=colname, color=color,  zorder=3, height=0.8)\n",
    "        if i ==0:\n",
    "            xcenters = widths/2 + minx/2\n",
    "        else:\n",
    "            xcenters = starts + widths / 2\n",
    "        for y, (x, c) in enumerate(zip(xcenters, widths)):\n",
    "            if c > 0:\n",
    "                axes[colx].text(x, y, str(c), ha='center', va='center', fontsize=10, color='black')\n",
    "    axes[colx].grid(color = 'white', linestyle = '-', linewidth = 2, alpha=1, zorder=0)\n",
    "    plt.setp(axes[colx].spines.values(), color='white')\n",
    "    axes[colx].set_facecolor('whitesmoke')\n",
    "    axes[colx].set_title(ds_map[ds])\n",
    "    for label in axes[colx].get_yticklabels():\n",
    "        label.set_rotation(90)\n",
    "        label.set_va('center')   \n",
    "\n",
    "axes[3].set_xlabel(r'% of pixels')\n",
    "# fig.text(0.5, 0.90, 'PASCAL-Context', fontsize=16, ha='center')\n",
    "# fig.text(0.5, 0.47, 'COCO-Stuff-10K', fontsize=16, ha='center')\n",
    "handles, labels = axes[1].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', ncol=4, bbox_to_anchor=(0.5, 0.05))\n",
    "plt.savefig('graph_images/dist_bar_all.pdf', bbox_inches=\"tight\")\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hrnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
