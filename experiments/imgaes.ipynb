{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading from /BS/mlcysec2/work/hierarchical-certification/log/cityscapes/images:  70%|██████▉   | 348/500 [02:09<01:22,  1.85it/s]"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import copy\n",
    "import plotly.express as px\n",
    "\n",
    "num_classes = 19\n",
    "exp = 'images'\n",
    "\n",
    "image_keys = ['image_np01', 'label', 'classes_certify', 'boundary_map', 'gt_adaptive_label']\n",
    "def read_exp_dir(ds, exp='table'):\n",
    "    exp_dir = f'/BS/mlcysec2/work/hierarchical-certification/log/{ds}/{exp}'\n",
    "    overall_dict = {}\n",
    "    for file in tqdm(glob.glob(os.path.join(exp_dir, '*.pkl'))[:30], desc=f'reading from {exp_dir}'):\n",
    "        d = pickle.load(open(file, 'rb'))\n",
    "        filename = os.path.basename(file).replace('.pkl', '')\n",
    "        overall_dict[filename] = {}\n",
    "        for image_name, image_d in d.items():\n",
    "            for model_type, model_d in image_d.items():\n",
    "                if model_type not in overall_dict:\n",
    "                    overall_dict[filename][model_type] = {}\n",
    "                for metric, value in model_d.items():\n",
    "                    overall_dict[filename][model_type][metric] = value\n",
    "                        \n",
    "    return overall_dict\n",
    "\n",
    "dir_dict = {}\n",
    "for ds in ['cityscapes', 'acdc', 'cocostuff', 'pascal_ctx']:\n",
    "    dir_dict[ds] = read_exp_dir(ds, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_rgb(h):\n",
    "    if '#' in h:\n",
    "        h = h.lstrip('#')\n",
    "        return tuple(int(h[i:i+2], 16) for i in (0, 2, 4))\n",
    "    else:\n",
    "        return eval(h.replace('rgb', ''))\n",
    "    \n",
    "cs_color_dict = {'road': px.colors.qualitative.Dark24[5],  # street - dark gray\n",
    "'sidewalk': px.colors.qualitative.Set1[8], # sidewalk - brighter gray\n",
    "'building': px.colors.qualitative.Antique[5], # building - \n",
    "'wall': px.colors.qualitative.T10[9], # wall - \n",
    "'fence': px.colors.qualitative.Pastel1[6], # fence - \n",
    "'pole': px.colors.qualitative.Bold[4], # pole - \n",
    "'traffic light': px.colors.qualitative.Set2[5], # traffic light - \n",
    "'traffic sign': px.colors.qualitative.Set1[5], # traffic sign - \n",
    "'vegetation': px.colors.qualitative.Dark24[2], # vegetation\n",
    "'terrain': px.colors.qualitative.G10[7], # terrain\n",
    "'sky': px.colors.qualitative.Plotly[5], # sky\n",
    "'person': px.colors.qualitative.Set1[0], # person\n",
    "'rider': px.colors.qualitative.T10[6], # rider\n",
    "'car': px.colors.qualitative.Dark24[9], # car\n",
    "'truck': px.colors.qualitative.Alphabet[1], # truck\n",
    "'bus': px.colors.qualitative.Dark24[19], # bus\n",
    "'train': px.colors.qualitative.D3[9], # train\n",
    "'motorcycle': px.colors.qualitative.Pastel[0], # motorcycle\n",
    "'bicycle': px.colors.qualitative.Pastel[9], # bicycle\n",
    "'construction & vegetation': px.colors.qualitative.Alphabet[5],\n",
    "'traffic-sign': px.colors.qualitative.Set2[1],\n",
    "'human':px.colors.qualitative.Vivid[9],\n",
    "'vehicle': px.colors.qualitative.Alphabet[13],\n",
    "'static obstacle': px.colors.qualitative.Pastel[5],\n",
    "'dynamic obstacle': px.colors.qualitative.Set3[9],\n",
    "'flat obstacle':px.colors.qualitative.Pastel[10],\n",
    "'obstacle': px.colors.qualitative.T10[8] \n",
    "}\n",
    "cs_color_pallette = np.array([hex_to_rgb(c) for c in cs_color_dict.values()]+[(255, 255, 255)]*(256-len(cs_color_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n",
      "(1024, 2048, 3) (2097152,) (1024, 2048, 3) (1024, 2048, 3) (1024, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "graph_images_pth = '/BS/mlcysec2/work/hierarchical-certification/graph_images/images'\n",
    "\n",
    "dataset_palette = {'cityscapes': cs_color_pallette}\n",
    "for ds, ds_dict in dir_dict.items():\n",
    "    for im_filename, im_dict in ds_dict.items():\n",
    "        for model_type, model_d in im_dict.items():\n",
    "            for k, v in model_d.items():\n",
    "                if k == 'image_np01':\n",
    "                    image_np01 = v\n",
    "                if k == 'boundary_map':\n",
    "                    boundary_map = v\n",
    "                if k == 'label':\n",
    "                    label = v\n",
    "                if k == 'classes_certify':\n",
    "                    if isinstance(model_type, tuple):\n",
    "                        n, n0, f, hi, sigma, tau = model_type\n",
    "                        if f == None:\n",
    "                            seg_classes_certify = v\n",
    "                        else:\n",
    "                            ada_classes_certify = v\n",
    "        outdir = os.path.join(graph_images_pth, im_filename.split('.')[0])\n",
    "        w, h, c = image_np01.shape\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "        cv2.imwrite(os.path.join(outdir, 'image_np01.png'), image_np01[...,::-1]*255)\n",
    "        cv2.imwrite(os.path.join(outdir, 'boundary_map.png'), boundary_map.reshape((w, h))*255)\n",
    "        cv2.imwrite(os.path.join(outdir, 'boundary_map.png'), (1-boundary_map).reshape((w, h))*255)\n",
    "        boundary_idx = boundary_map == 1\n",
    "        non_boundary_idx = boundary_map == 0\n",
    "        ada_abstain_idx = ada_classes_certify == 254\n",
    "        seg_abstain_idx = seg_classes_certify == 254\n",
    "\n",
    "        zeros = np.zeros((w*h))\n",
    "        zeros[seg_classes_certify == 254] = 255\n",
    "        abstain_seg = zeros.reshape((w, h))\n",
    "        cv2.imwrite(os.path.join(outdir, 'seg_abstain_map.png'), abstain_seg)\n",
    "        \n",
    "        zeros = np.zeros((w*h))\n",
    "        zeros[ada_classes_certify == 254] = 255\n",
    "        abstain_ada = zeros.reshape((w, h))\n",
    "        cv2.imwrite(os.path.join(outdir, 'ada_abstain_map.png'), abstain_ada)\n",
    "\n",
    "        zeros = np.zeros((w*h))\n",
    "        zeros[ada_abstain_idx & boundary_idx] = 255\n",
    "        cv2.imwrite(os.path.join(outdir, 'ada_inter_abstain_boundary.png'), zeros.reshape((w, h)))\n",
    "        zeros = np.zeros((w*h))\n",
    "        zeros[ada_abstain_idx & non_boundary_idx] = 255\n",
    "        cv2.imwrite(os.path.join(outdir, 'ada_inter_abstain_non_boundary.png'), zeros.reshape((w, h)))\n",
    "        \n",
    "        zeros = np.zeros((w*h))\n",
    "        zeros[seg_abstain_idx & boundary_idx] = 255\n",
    "        cv2.imwrite(os.path.join(outdir, 'seg_inter_abstain_boundary.png'), zeros.reshape((w, h)))\n",
    "        zeros = np.zeros((w*h))\n",
    "        abstain_idx = seg_classes_certify == 254\n",
    "        zeros[seg_abstain_idx & non_boundary_idx] = 255\n",
    "        cv2.imwrite(os.path.join(outdir, 'seg_inter_abstain_non_boundary.png'), zeros.reshape((w, h)))   \n",
    "        \n",
    "        p = dataset_palette[ds]\n",
    "        label = p[label].reshape((w, h, c))\n",
    "        \n",
    "        cv2.imwrite(os.path.join(outdir, 'label.png'), label[...,::-1])\n",
    "        \n",
    "        p = dataset_palette[ds]\n",
    "        seg_classes_certify = p[seg_classes_certify].reshape((w, h, c))\n",
    "        cv2.imwrite(os.path.join(outdir, 'seg_classes_certify.png'), seg_classes_certify[...,::-1])\n",
    "        \n",
    "        p = dataset_palette[ds]\n",
    "        ada_classes_certify = p[ada_classes_certify].reshape((w, h, c))\n",
    "        cv2.imwrite(os.path.join(outdir, 'ada_classes_certify.png'), ada_classes_certify[...,::-1])\n",
    "            \n",
    "\n",
    "        superimposed_gt = cv2.addWeighted(label.astype(np.uint), 0.6, (image_np01*255).astype(np.uint), 0.4, 0)\n",
    "        superimposed_ada = cv2.addWeighted(ada_classes_certify.astype(np.uint), 0.6, (image_np01*255).astype(np.uint), 0.4, 0)\n",
    "        superimposed_ada[ada_classes_certify == (255, 255, 255)] = 255\n",
    "        superimposed_seg = cv2.addWeighted(seg_classes_certify.astype(np.uint), 0.6, (image_np01*255).astype(np.uint), 0.4, 0)\n",
    "        superimposed_seg[seg_classes_certify == (255, 255, 255)] = 255\n",
    "        \n",
    "        cv2.imwrite(os.path.join(outdir, 'label_im.png'), superimposed_gt[...,::-1])\n",
    "        cv2.imwrite(os.path.join(outdir, 'ada_im_classes_certify.png'), superimposed_ada[...,::-1])\n",
    "        cv2.imwrite(os.path.join(outdir, 'seg_im_classes_certify.png'), superimposed_seg[...,::-1])\n",
    "\n",
    "        print(image_np01.shape, boundary_map.shape, label.shape, seg_classes_certify.shape, ada_classes_certify.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hrnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
